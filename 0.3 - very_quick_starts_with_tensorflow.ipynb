{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb04af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Zhengxiang (Jack) Wang \n",
    "# Date: 2022-01-19\n",
    "# GitHub: https://github.com/jaaack-wang "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd2c37",
   "metadata": {},
   "source": [
    "## Get TensorFlow\n",
    "\n",
    "In case you have not installed TensorFlow, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92cb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Requires the latest pip\n",
    "# !pip3 install --upgrade pip\n",
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e728e7",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "In case you have not run the `1 - get_data.ipynb`, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cc11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
    "# import get_data\n",
    "\n",
    "# get_data.get_quora_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150aa034",
   "metadata": {},
   "source": [
    "## Preprocess and numericalize text data\n",
    "\n",
    "In case you have not run the `2 - preprocess_data.ipynb`, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741b52bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two vocabulary dictionaries have been built!\n",
      "Please call \u001b[1mX.vocab_to_idx | X.idx_to_vocab\u001b[0m to find out more where [X] stands for the name you used for this TextVectorizer class.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "# ---- load dataset ----\n",
    "train_set, dev_set, test_set = load_dataset(['train.txt', 'dev.txt', 'test.txt'])\n",
    "\n",
    "# ---- numericalize the train set ----\n",
    "V = TextVectorizer(tokenize) \n",
    "text = gather_text(train_set) # for collecting texts from train set\n",
    "V.build_vocab(text) # for building mapping vocab_to_idx dictionary and text_encoder\n",
    "train_set_encoded = list(encode_dataset(train_set, encoder=V.text_encoder)) # encodoing train set\n",
    "dev_set_encoded = list(encode_dataset(dev_set, encoder=V.text_encoder)) # encodoing dev set for validation\n",
    "test_set_encoded  = list(encode_dataset(test_set, encoder=V.text_encoder)) # encodoing dev set for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60dbc74",
   "metadata": {},
   "source": [
    "### A note\n",
    "\n",
    "There are multiple ways to use tensorflow to train a model, but the easiest one is to employ the `fit` method. In this `fit` function, the `inputs` and `targets` (labels) from the train set should be separately provided, and the `inputs` and `targets` from the dev set should be put inside a list or tuple. And both the `inputs` and `targets` should not be batched, as there is another builtin parameter called `batch_size` that will create mini batches for us. Nevertheless, to maintain consistency, this tutorial decided to still use the `build_batches` function that we will build together later in other tutorials. This `build_batches` function will help normalize the text seq length, which tensorflow's `fit` method does not provide. \n",
    "\n",
    "A better way of using packages in the tensorflow ecosystem to preprocess and numericalize text data will be introduced separately, just as what I intended to do for the other two deep learning frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73e9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- build mini batches for the train and dev set ----\n",
    "train_set_batched = build_batches(train_set_encoded, batch_size=3000, include_seq_len=False)\n",
    "dev_set_batched = build_batches(dev_set_encoded, batch_size=1000, include_seq_len=False)\n",
    "test_set_batched = build_batches(test_set_encoded, batch_size=1000, include_seq_len=False)\n",
    "\n",
    "train_X1, train_X2, train_Y = train_set_batched[0]\n",
    "dev_X1, dev_X2, dev_Y = dev_set_batched[0]\n",
    "test_X1, test_X2, test_Y = test_set_batched[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052945f",
   "metadata": {},
   "source": [
    "## Training and evaluating models \n",
    "\n",
    "### BoW (Bag of Words) model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebd670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_models.BoW import BoW\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4376e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 23:47:39.949779: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-19 23:47:40.685039: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 1s 10ms/step - loss: 0.6805 - accuracy: 0.5623 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.6124 - accuracy: 0.6657 - val_loss: 0.6586 - val_accuracy: 0.6040\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.5446 - accuracy: 0.7467 - val_loss: 0.6192 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4564 - accuracy: 0.8337 - val_loss: 0.6090 - val_accuracy: 0.6590\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8733 - val_loss: 0.6110 - val_accuracy: 0.6570\n",
      "CPU times: user 6.15 s, sys: 999 ms, total: 7.15 s\n",
      "Wall time: 3.21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6135389a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BoW(len(V.vocab_to_idx), 1)\n",
    "model.compile(optimizer=keras.optimizers.Adam(5e-4),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[[\"accuracy\"]])\n",
    "\n",
    "%time model.fit([train_X1, train_X2], train_Y, epochs=5, batch_size=64, validation_data=([dev_X1, dev_X2], dev_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2550081",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed45b7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.6680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6093695759773254, 0.6679999828338623]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_X1, test_X2], test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c471c",
   "metadata": {},
   "source": [
    "### CNN (Convolutional Neural Network) model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5de7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 2s 32ms/step - loss: 0.6896 - accuracy: 0.5567 - val_loss: 0.6817 - val_accuracy: 0.6200\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.6411 - accuracy: 0.7313 - val_loss: 0.6442 - val_accuracy: 0.6280\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.4901 - accuracy: 0.8133 - val_loss: 0.6240 - val_accuracy: 0.6890\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.2682 - accuracy: 0.9107 - val_loss: 0.7409 - val_accuracy: 0.6540\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.1152 - accuracy: 0.9670 - val_loss: 0.9151 - val_accuracy: 0.6500\n",
      "CPU times: user 28.3 s, sys: 7.88 s, total: 36.2 s\n",
      "Wall time: 7.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5f671ff70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_models.CNN import CNN\n",
    "\n",
    "model = CNN(len(V.vocab_to_idx), 1)\n",
    "model.compile(optimizer=keras.optimizers.Adam(5e-4),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[[\"accuracy\"]])\n",
    "\n",
    "%time model.fit([train_X1, train_X2], train_Y, epochs=5, batch_size=64, validation_data=([dev_X1, dev_X2], dev_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9502c1",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1838b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9565 - accuracy: 0.6190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9565356969833374, 0.6190000176429749]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_X1, test_X2], test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285af7c",
   "metadata": {},
   "source": [
    "## RNN (Recurrent neural network) models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d14c7",
   "metadata": {},
   "source": [
    "### Simple RNN model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7706134f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 4s 40ms/step - loss: 0.6783 - accuracy: 0.5617 - val_loss: 0.6489 - val_accuracy: 0.6030\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.5395 - accuracy: 0.7383 - val_loss: 0.6443 - val_accuracy: 0.6370\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.3117 - accuracy: 0.8883 - val_loss: 0.7628 - val_accuracy: 0.6340\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.1100 - accuracy: 0.9677 - val_loss: 0.9975 - val_accuracy: 0.6210\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0417 - accuracy: 0.9907 - val_loss: 1.1667 - val_accuracy: 0.6370\n",
      "CPU times: user 33.2 s, sys: 9.99 s, total: 43.2 s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5f68e4130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_models.S_RNN import SimpleRNN\n",
    "\n",
    "model = SimpleRNN(len(V.vocab_to_idx), 1, bidirectional=False)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(5e-4),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[[\"accuracy\"]])\n",
    "\n",
    "%time model.fit([train_X1, train_X2], train_Y, epochs=5, batch_size=64, validation_data=([dev_X1, dev_X2], dev_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863367e",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001e85d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2218 - accuracy: 0.6190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.221795916557312, 0.6190000176429749]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_X1, test_X2], test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f869",
   "metadata": {},
   "source": [
    "### GRU (Gated recurrent units) model \n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845b36b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 10s 104ms/step - loss: 0.6915 - accuracy: 0.5353 - val_loss: 0.6884 - val_accuracy: 0.5880\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 3s 68ms/step - loss: 0.6171 - accuracy: 0.7170 - val_loss: 0.6209 - val_accuracy: 0.6610\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 3s 70ms/step - loss: 0.3772 - accuracy: 0.8453 - val_loss: 0.7429 - val_accuracy: 0.6260\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 3s 67ms/step - loss: 0.1799 - accuracy: 0.9407 - val_loss: 0.9252 - val_accuracy: 0.6240\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 3s 67ms/step - loss: 0.0887 - accuracy: 0.9747 - val_loss: 1.2896 - val_accuracy: 0.6290\n",
      "CPU times: user 1min 15s, sys: 19.8 s, total: 1min 34s\n",
      "Wall time: 22.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5f7b10580>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_models.GRU import GRU\n",
    "\n",
    "model = GRU(len(V.vocab_to_idx), 1, bidirectional=False)\n",
    "model.compile(optimizer=keras.optimizers.Adam(5e-4),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[[\"accuracy\"]])\n",
    "\n",
    "%time model.fit([train_X1, train_X2], train_Y, epochs=5, batch_size=64, validation_data=([dev_X1, dev_X2], dev_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff6932",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce7a2b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 8ms/step - loss: 1.3176 - accuracy: 0.6110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3175928592681885, 0.6110000014305115]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_X1, test_X2], test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d9863",
   "metadata": {},
   "source": [
    "### LSTM (Long short-term memory) model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11223765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 11s 130ms/step - loss: 0.6831 - accuracy: 0.5700 - val_loss: 0.6531 - val_accuracy: 0.6200\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 4s 96ms/step - loss: 0.5764 - accuracy: 0.7153 - val_loss: 0.6018 - val_accuracy: 0.6650\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.4192 - accuracy: 0.8303 - val_loss: 0.6325 - val_accuracy: 0.6590\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.2442 - accuracy: 0.9130 - val_loss: 0.8302 - val_accuracy: 0.6650\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.1267 - accuracy: 0.9623 - val_loss: 1.0756 - val_accuracy: 0.6540\n",
      "CPU times: user 1min 33s, sys: 26.3 s, total: 1min 59s\n",
      "Wall time: 28.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6004d1670>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_models.LSTM import LSTM\n",
    "\n",
    "model = LSTM(len(V.vocab_to_idx), 1, bidirectional=False)\n",
    "model.compile(optimizer=keras.optimizers.Adam(5e-4),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[[\"accuracy\"]])\n",
    "\n",
    "%time model.fit([train_X1, train_X2], train_Y, epochs=5, batch_size=64, validation_data=([dev_X1, dev_X2], dev_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f1abd",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "263dc104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 16ms/step - loss: 1.0836 - accuracy: 0.6570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0836219787597656, 0.6570000052452087]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_X1, test_X2], test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
