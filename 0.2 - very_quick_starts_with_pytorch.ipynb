{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb04af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Zhengxiang (Jack) Wang \n",
    "# Date: 2022-01-17\n",
    "# GitHub: https://github.com/jaaack-wang "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd2c37",
   "metadata": {},
   "source": [
    "## Get PyTorch\n",
    "\n",
    "In case you have not installed PyTorch,run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92cb1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/site-packages (1.9.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision) (8.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torchvision) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e728e7",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "In case you have not run the `1 - get_data.ipynb`, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cc11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-17 23:48:19--  http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
      "Resolving qim.fs.quoracdn.net (qim.fs.quoracdn.net)... 151.101.53.2\n",
      "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|151.101.53.2|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 58176133 (55M) [text/tab-separated-values]\n",
      "Saving to: ‘quora_duplicate_questions.tsv’\n",
      "\n",
      "quora_duplicate_que 100%[===================>]  55.48M  9.60MB/s    in 10s     \n",
      "\n",
      "2022-01-17 23:48:31 (5.37 MB/s) - ‘quora_duplicate_questions.tsv’ saved [58176133/58176133]\n",
      "\n",
      "train.txt has been saved!\n",
      "dev.txt has been saved!\n",
      "test.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
    "import get_data\n",
    "\n",
    "get_data.get_quora_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150aa034",
   "metadata": {},
   "source": [
    "## Preprocess and numericalize text data\n",
    "\n",
    "In case you have not run the `2 - preprocess_data.ipynb`, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741b52bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two vocabulary dictionaries have been built!\n",
      "Please call \u001b[1mX.vocab_to_idx | X.idx_to_vocab\u001b[0m to find out more where [X] stands for the name you used for this TextVectorizer class.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "# ---- load dataset ----\n",
    "train_set, dev_set, test_set = load_dataset(['train.txt', 'dev.txt', 'test.txt'])\n",
    "\n",
    "# ---- numericalize the train set ----\n",
    "V = TextVectorizer(tokenize) \n",
    "text = gather_text(train_set) # for collecting texts from train set\n",
    "V.build_vocab(text) # for building mapping vocab_to_idx dictionary and text_encoder\n",
    "train_set_encoded = list(encode_dataset(train_set, encoder=V.text_encoder)) # encodoing train set\n",
    "dev_set_encoded = list(encode_dataset(dev_set, encoder=V.text_encoder)) # encodoing dev set for validation\n",
    "test_set_encoded  = list(encode_dataset(test_set, encoder=V.text_encoder)) # encodoing dev set for prediction\n",
    "\n",
    "# ---- build mini batches for the train and dev set ----\n",
    "train_set_batched = build_batches(train_set_encoded, batch_size=64, include_seq_len=False)\n",
    "dev_set_batched = build_batches(dev_set_encoded, batch_size=64, include_seq_len=False)\n",
    "test_set_batched = build_batches(test_set_encoded, batch_size=64, include_seq_len=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a76e3d1",
   "metadata": {},
   "source": [
    "### Convert numpy arrays into tensors\n",
    "\n",
    "It turns out that pytorch models do not accept numpy arrays during model training. The problem seems to be an attribute associated with `torch.Tensor` that has been named differently in `numpy.ndarray`, unlike `paddle`. \n",
    "\n",
    "To maintain consistency, this tutorial decided to not change the functions we will build together in the later tutorials. A better way of using packages in the pytorch ecosystem to preprocess and numericalize text data will be introduced separately, just as what I intended to do for the other two deep learning frameworks.\n",
    "\n",
    "Likewise, `PyTorchUtils` is also a wrapped up class I wrote up just to get this quick starts going, which will also be introduced later. Although this is not the best practice of using `pytorch`, you will find it useful when realizing the very nuanced differences between different deep learning frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696236b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_utils import to_tensor\n",
    "\n",
    "train_set_batched = to_tensor(train_set_batched)\n",
    "dev_set_batched = to_tensor(dev_set_batched)\n",
    "test_set_batched = to_tensor(test_set_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052945f",
   "metadata": {},
   "source": [
    "## Training and evaluating models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a72668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_utils import PyTorchUtils\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18d597",
   "metadata": {},
   "source": [
    "### BoW (Bag of Words) model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4376e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 {'Train loss': '0.70698', 'Train accu': '33.94'}\n",
      "Validation... {'Dev loss': '0.68095', 'Dev accu': '39.86'}\n",
      "\n",
      "Epoch 2/5 {'Train loss': '0.64689', 'Train accu': '49.47'}\n",
      "Validation... {'Dev loss': '0.66661', 'Dev accu': '47.07'}\n",
      "\n",
      "Epoch 3/5 {'Train loss': '0.61382', 'Train accu': '57.27'}\n",
      "Validation... {'Dev loss': '0.66069', 'Dev accu': '49.94'}\n",
      "\n",
      "Epoch 4/5 {'Train loss': '0.58215', 'Train accu': '63.16'}\n",
      "Validation... {'Dev loss': '0.65781', 'Dev accu': '51.88'}\n",
      "\n",
      "Epoch 5/5 {'Train loss': '0.54909', 'Train accu': '67.14'}\n",
      "Validation... {'Dev loss': '0.65696', 'Dev accu': '54.36'}\n",
      "\n",
      "CPU times: user 3.46 s, sys: 227 ms, total: 3.68 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "from pytorch_models.BoW import BoW\n",
    "\n",
    "\n",
    "model = BoW(len(V.vocab_to_idx), 2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "PT = PyTorchUtils(model, optimizer, criterion, include_seq_len=False)\n",
    "%time PT.train(train_set_batched, dev_set_batched, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2550081",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed45b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test loss': '0.64489', 'Test accu': '55.23'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT.evaluate(test_set_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c471c",
   "metadata": {},
   "source": [
    "### CNN (Convolutional Neural Network) model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5de7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 {'Train loss': '0.68896', 'Train accu': '31.35'}\n",
      "Validation... {'Dev loss': '0.67878', 'Dev accu': '53.59'}\n",
      "\n",
      "Epoch 2/5 {'Train loss': '0.64433', 'Train accu': '59.66'}\n",
      "Validation... {'Dev loss': '0.65398', 'Dev accu': '57.85'}\n",
      "\n",
      "Epoch 3/5 {'Train loss': '0.57345', 'Train accu': '70.37'}\n",
      "Validation... {'Dev loss': '0.63968', 'Dev accu': '60.64'}\n",
      "\n",
      "Epoch 4/5 {'Train loss': '0.46555', 'Train accu': '79.54'}\n",
      "Validation... {'Dev loss': '0.65233', 'Dev accu': '61.27'}\n",
      "\n",
      "Epoch 5/5 {'Train loss': '0.33501', 'Train accu': '88.75'}\n",
      "Validation... {'Dev loss': '0.68868', 'Dev accu': '61.35'}\n",
      "\n",
      "CPU times: user 12.8 s, sys: 2.54 s, total: 15.4 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "from pytorch_models.CNN import CNN\n",
    "\n",
    "\n",
    "model = CNN(len(V.vocab_to_idx), 2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "PT = PyTorchUtils(model, optimizer, criterion, include_seq_len=False)\n",
    "%time PT.train(train_set_batched, dev_set_batched, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9502c1",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1838b0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test loss': '0.65676', 'Test accu': '64.84'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT.evaluate(test_set_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285af7c",
   "metadata": {},
   "source": [
    "## RNN (Recurrent neural network) models\n",
    "\n",
    "As the RNN models also take as an input the sequence length, we need to re-encode the train set, dev set, and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8764b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- build mini batches for the train and dev set ----\n",
    "train_set_batched = build_batches(train_set_encoded, batch_size=64, include_seq_len=True)\n",
    "dev_set_batched = build_batches(dev_set_encoded, batch_size=64, include_seq_len=True)\n",
    "test_set_batched = build_batches(test_set_encoded, batch_size=64, include_seq_len=True)\n",
    "\n",
    "train_set_batched = to_tensor(train_set_batched)\n",
    "dev_set_batched = to_tensor(dev_set_batched)\n",
    "test_set_batched = to_tensor(test_set_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d14c7",
   "metadata": {},
   "source": [
    "### Simple RNN model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7706134f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 {'Train loss': '0.69128', 'Train accu': '35.06'}\n",
      "Validation... {'Dev loss': '0.68908', 'Dev accu': '40.62'}\n",
      "\n",
      "Epoch 2/5 {'Train loss': '0.66777', 'Train accu': '56.48'}\n",
      "Validation... {'Dev loss': '0.68243', 'Dev accu': '50.10'}\n",
      "\n",
      "Epoch 3/5 {'Train loss': '0.62369', 'Train accu': '65.12'}\n",
      "Validation... {'Dev loss': '0.68859', 'Dev accu': '55.14'}\n",
      "\n",
      "Epoch 4/5 {'Train loss': '0.55485', 'Train accu': '71.34'}\n",
      "Validation... {'Dev loss': '0.72700', 'Dev accu': '55.35'}\n",
      "\n",
      "Epoch 5/5 {'Train loss': '0.47938', 'Train accu': '77.40'}\n",
      "Validation... {'Dev loss': '0.78453', 'Dev accu': '55.94'}\n",
      "\n",
      "CPU times: user 7.52 s, sys: 1.25 s, total: 8.77 s\n",
      "Wall time: 5.24 s\n"
     ]
    }
   ],
   "source": [
    "from pytorch_models.S_RNN import SimpleRNN\n",
    "\n",
    "\n",
    "model = SimpleRNN(len(V.vocab_to_idx), 2, bidirectional=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "PT = PyTorchUtils(model, optimizer, criterion, include_seq_len=True)\n",
    "%time PT.train(train_set_batched, dev_set_batched, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863367e",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "001e85d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test loss': '0.73299', 'Test accu': '59.28'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT.evaluate(test_set_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f869",
   "metadata": {},
   "source": [
    "### GRU (Gated recurrent units) model \n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "845b36b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 {'Train loss': '0.69199', 'Train accu': '40.32'}\n",
      "Validation... {'Dev loss': '0.68728', 'Dev accu': '45.27'}\n",
      "\n",
      "Epoch 2/5 {'Train loss': '0.67196', 'Train accu': '55.40'}\n",
      "Validation... {'Dev loss': '0.67283', 'Dev accu': '55.06'}\n",
      "\n",
      "Epoch 3/5 {'Train loss': '0.62632', 'Train accu': '64.53'}\n",
      "Validation... {'Dev loss': '0.65178', 'Dev accu': '60.68'}\n",
      "\n",
      "Epoch 4/5 {'Train loss': '0.55954', 'Train accu': '71.28'}\n",
      "Validation... {'Dev loss': '0.65149', 'Dev accu': '62.83'}\n",
      "\n",
      "Epoch 5/5 {'Train loss': '0.48512', 'Train accu': '76.65'}\n",
      "Validation... {'Dev loss': '0.67842', 'Dev accu': '62.15'}\n",
      "\n",
      "CPU times: user 14.4 s, sys: 4.09 s, total: 18.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "from pytorch_models.GRU import GRU\n",
    "\n",
    "\n",
    "model = GRU(len(V.vocab_to_idx), 2, bidirectional=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "PT = PyTorchUtils(model, optimizer, criterion, include_seq_len=True)\n",
    "%time PT.train(train_set_batched, dev_set_batched, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff6932",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7a2b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test loss': '0.67833', 'Test accu': '60.86'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT.evaluate(test_set_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d9863",
   "metadata": {},
   "source": [
    "### LSTM (Long short-term memory) model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11223765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 {'Train loss': '0.69284', 'Train accu': '45.27'}\n",
      "Validation... {'Dev loss': '0.68995', 'Dev accu': '43.09'}\n",
      "\n",
      "Epoch 2/5 {'Train loss': '0.67827', 'Train accu': '53.87'}\n",
      "Validation... {'Dev loss': '0.67460', 'Dev accu': '57.54'}\n",
      "\n",
      "Epoch 3/5 {'Train loss': '0.61445', 'Train accu': '65.91'}\n",
      "Validation... {'Dev loss': '0.64512', 'Dev accu': '60.49'}\n",
      "\n",
      "Epoch 4/5 {'Train loss': '0.53654', 'Train accu': '73.67'}\n",
      "Validation... {'Dev loss': '0.65003', 'Dev accu': '60.53'}\n",
      "\n",
      "Epoch 5/5 {'Train loss': '0.45890', 'Train accu': '78.61'}\n",
      "Validation... {'Dev loss': '0.68671', 'Dev accu': '61.33'}\n",
      "\n",
      "CPU times: user 18.2 s, sys: 4.87 s, total: 23 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "from pytorch_models.LSTM import LSTM\n",
    "\n",
    "\n",
    "model = LSTM(len(V.vocab_to_idx), 2, bidirectional=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "PT = PyTorchUtils(model, optimizer, criterion, include_seq_len=True)\n",
    "%time PT.train(train_set_batched, dev_set_batched, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f1abd",
   "metadata": {},
   "source": [
    "#### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263dc104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test loss': '0.68404', 'Test accu': '62.68'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT.evaluate(test_set_batched)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
